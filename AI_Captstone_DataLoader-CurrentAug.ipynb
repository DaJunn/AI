{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "# Capstone: Data Loader\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import the relevant modules to be used later\nfrom __future__ import print_function\nimport gzip\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport shutil\nimport struct\nimport sys\n\ntry: \n    from urllib.request import urlretrieve \nexcept ImportError: \n    from urllib import urlretrieve\n\n# Config matplotlib for inline plotting\n%matplotlib inline",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/matplotlib/font_manager.py:281: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data download\n\nWe will download the data onto the local machine. The MNIST database is a standard set of handwritten digits that has been widely used for training and testing of machine learning algorithms. It has a training set of 60,000 images and a test set of 10,000 images with each image being 28 x 28 grayscale pixels. This set is easy to use visualize and train on any computer."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Functions to load MNIST images and unpack into train and test set.\n# - loadData reads image data and formats into a 28x28 long array\n# - loadLabels reads the corresponding labels data, 1 for each image\n# - try_build packs the downloaded image and labels data into a combined format to be read later by \n#   CNTK text reader \n\nfrom skimage import io\nimport matplotlib.pyplot as plt\nfrom numpy import genfromtxt\n\n\ndef loadData(pathSrc, type, cimg, crow=128, ccol=118):\n    try:\n        # for each png in the path\n        # Read data.\n        # this read intup numpy array\n        init = True\n        for item in sorted(os.listdir(pathSrc)): # loop through items in dir\n            if item.endswith(type+\".png\"): # check for \".png\" extension\n                #print(\"   reading PNG {0} ...\".format(item))\n                file_name = os.path.join(pathSrc,item) # get full path of files\n             \n                if (init):\n                    res =  np.ravel(io.imread(file_name,as_grey=True))\n                    init = False\n                else:\n                    res = np.vstack( (res, np.ravel(io.imread(file_name,as_grey=True))) )\n    finally:\n        print(\"   Done loading images\")\n        \n    return res\n\n\n\ndef loadLabels(pathSrc, cimg):\n    try:\n        # Read labels.\n        #res = np.fromstring(gz.read(cimg), dtype = np.uint8)\n        print(\"   Loading labels\")\n        \n        #skip the header\n        label_data = genfromtxt(pathSrc, delimiter=',',skip_header=1)\n        num_rows, num_cols = label_data.shape\n        #1-hot encode\n        init = True\n        for row in range(num_rows):\n            \n            if(init):\n                res = np.array(int(label_data[row][1]))\n                init = False\n            else:\n                res = np.vstack( (res, int(np.array(label_data[row][1]) )  ) )\n                               \n    finally:\n        print(\"   Done loading labels\")\n    \n    return res\n\ndef try_build(dataSrc, labelsSrc, cimg):\n    data = loadData(dataSrc, cimg)\n    labels = loadLabels(labelsSrc, cimg)\n    return np.hstack((data, labels))\n\n",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aLabel = loadLabels(\"/home/nbuser/library/data/Capstone/train_labels.csv\", 5)\nprint(aLabel.shape)\n",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "   Loading labels\n   Done loading labels\n(988, 1)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aData_c1 = loadData(\"/home/nbuser/library/data/Capstone/train\",\"_c\", 1, 128,118 )\nprint(aData_c1.shape)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "   Done loading images\n(988, 15104)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(aData_c1.shape)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(988, 15104)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aData_c2 = loadData(\"/home/nbuser/library/data/Capstone/train\",\"_c - Copy\", 1, 128,118 )\nprint(aData_c2.shape)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "   Done loading images\n(988, 15104)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aData_c3 = loadData(\"/home/nbuser/library/data/Capstone/train\",\"_c - Copy (2)\", 1, 128,118 )\nprint(aData_c3.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "aData_c4 = loadData(\"/home/nbuser/library/data/Capstone/train\",\"_c - Copy (3)\", 1, 128,118 )\nprint(aData_c4.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_c1 = np.hstack((aData_c1, aLabel))\nprint(train_c1.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_c2 = np.hstack((aData_c2, aLabel))\nprint(train_c2.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_c3 = np.hstack((aData_c3, aLabel))\nprint(train_c3.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_c4 = np.hstack((aData_c4, aLabel))\nprint(train_c4.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_join = np.vstack((train_c1, train_c2, train_c3, train_c4))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Save the images\n\nSave the images in a local directory. While saving the data we flatten the images to a vector (128x118 image pixels becomes an array of length 15104 data points).\n\n\nThe labels are encoded as [1-hot][] encoding (label of 3 with 11 digits becomes `00010000000`, where the first index corresponds to digit `0` and the last one corresponds to digit `9`.\n\n\n\n[1-hot]: https://en.wikipedia.org/wiki/One-hot"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Save the data files into a format compatible with CNTK text reader\n# there was something going on here where the labels were converted  to float and couldn't be used as index arrays\n# also had to increase the np.eye size to 11 since we have 11 labels\ndef savetxt(filename, ndarray):\n    dir = os.path.dirname(filename)\n\n    if not os.path.exists(dir):\n        os.makedirs(dir)\n\n    if not os.path.isfile(filename):\n        print(\"Saving\", filename )\n        with open(filename, 'w') as f:\n            labels = list(map(' '.join, np.eye(11, dtype=np.uint).astype(str)))\n            for row in ndarray:\n                row_str = row.astype(str)\n                #print(row[-1])\n                label_str = labels[int(row[-1])]\n                feature_str = ' '.join(row_str[:-1])\n                f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n    else:\n        print(\"File already exists\", filename)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Save the train and test files (prefer our default path for the data)\n\n#print ('Writing train_combo text file...')\n#savetxt(os.path.join(\"/home/nbuser/library/data/Capstone/\", \"Train_combo-128x118_cntk_text.txt\"), train_c)\n\nprint ('Writing train_c text file...')\nsavetxt(os.path.join(\"/home/nbuser/library/data/Capstone/\", \"Train_c_join-128x118_cntk_text.txt\"), train_join)\n\nprint('Done')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}